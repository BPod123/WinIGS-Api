{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthor: Dr. Sreenivas Bhattiprolu\\nDataset: https://www.kaggle.com/datamunge/sign-language-mnist\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Dr. Sreenivas Bhattiprolu\n",
    "Dataset: https://www.kaggle.com/datamunge/sign-language-mnist\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define epochs for all models.\n",
    "epochs = 10\n",
    "\n",
    "train = pd.read_csv('sign_mnist_train.csv')\n",
    "test = pd.read_csv('sign_mnist_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasets as numpy arrays\n",
    "train_data = np.array(train, dtype = 'float32')\n",
    "test_data = np.array(test, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define class labels for easy interpretation\n",
    "class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', \n",
    "               'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check - plot a few images and labels\n",
    "i = random.randint(1,train.shape[0])\n",
    "fig1, ax1 = plt.subplots(figsize=(2,2))\n",
    "plt.imshow(train_data[i,1:].reshape((28,28))) \n",
    "print(\"Label for the image is: \", class_names[int(train_data[i,0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data distribution visualization\n",
    "fig = plt.figure(figsize=(18,18))\n",
    "ax1 = fig.add_subplot(221)\n",
    "train['label'].value_counts().plot(kind='bar', ax=ax1)\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset seems to be fairly balanced.\n",
    "\n",
    "#Normalize / scale X values\n",
    "X_train = train_data[:, 1:] /255.\n",
    "X_test = test_data[:, 1:] /255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert y to categorical if planning on using categorical cross entropy\n",
    "#No need to do this if using sparse categorical cross entropy\n",
    "y_train = train_data[:, 0]\n",
    "y_train_cat = to_categorical(y_train, num_classes=25)\n",
    "\n",
    "y_test = test_data[:,0]\n",
    "y_test_cat = to_categorical(y_test, num_classes=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape for the neural network\n",
    "X_train = X_train.reshape(X_train.shape[0], *(28, 28, 1))\n",
    "X_test = X_test.reshape(X_test.shape[0], *(28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "#Model 1\n",
    "\n",
    "#Defining the Convolutional Neural Network\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(32, (3, 3), input_shape = (28,28,1), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model1.add(Dropout(0.2))\n",
    "\n",
    "model1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model1.add(Dropout(0.2))\n",
    "\n",
    "model1.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model1.add(Dropout(0.2))\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "model1.add(Dense(128, activation = 'relu'))\n",
    "model1.add(Dense(25, activation = 'softmax'))\n",
    "\n",
    "#If your targets are one-hot encoded, use categorical_crossentropy. Examples of one-hot encodings:\n",
    "# If your targets are integers, use sparse_categorical_crossentropy. \n",
    "\n",
    "#model1.compile(loss ='sparse_categorical_crossentropy', optimizer='adam', metrics =['acc'])\n",
    "model1.compile(loss ='categorical_crossentropy', optimizer='adam',metrics =['acc'])\n",
    "model1.summary()\n",
    "\n",
    "#Training the CNN model1\n",
    "#history = model1.fit(X_train, y_train, batch_size = 128, epochs = 10, verbose = 1, validation_data = (X_test, y_test))\n",
    "history1 = model1.fit(X_train, y_train_cat, batch_size = 128, epochs = epochs, verbose = 1, validation_data = (X_test, y_test_cat))\n",
    "\n",
    "model1.save('saved_models/model1.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#Model2\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(32, (3, 3), input_shape = (28,28,1), activation='relu'))\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model2.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model2.add(Conv2D(25, (1,1)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(25, activation = 'softmax'))\n",
    "\n",
    "model2.compile(loss ='categorical_crossentropy', optimizer='adam',metrics =['acc'])\n",
    "model2.summary()\n",
    "\n",
    "history2 = model2.fit(X_train, y_train_cat, batch_size = 128, epochs = epochs, verbose = 1, validation_data = (X_test, y_test_cat))\n",
    "\n",
    "model2.save('saved_models/model2.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#Model 3\n",
    "#\n",
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Conv2D(32, (3, 3), input_shape = (28,28,1), activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model3.add(Dropout(0.2))\n",
    "\n",
    "model3.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model3.add(Dropout(0.2))\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "model3.add(Dense(25, activation = 'softmax'))\n",
    "\n",
    "#If your targets are one-hot encoded, use categorical_crossentropy. Examples of one-hot encodings:\n",
    "# If your targets are integers, use sparse_categorical_crossentropy. \n",
    "\n",
    "#model1.compile(loss ='sparse_categorical_crossentropy', optimizer='adam', metrics =['acc'])\n",
    "model3.compile(loss ='categorical_crossentropy', optimizer='adam',metrics =['acc'])\n",
    "model3.summary()\n",
    "\n",
    "#Training the CNN model1\n",
    "#history = model1.fit(X_train, y_train, batch_size = 128, epochs = 10, verbose = 1, validation_data = (X_test, y_test))\n",
    "history3 = model3.fit(X_train, y_train_cat, batch_size = 128, epochs = epochs, verbose = 1, validation_data = (X_test, y_test_cat))\n",
    "\n",
    "model3.save('saved_models/model3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "### Model average / sum Ensemble\n",
    "# Simple sum of all outputs / predictions and argmax across all classes\n",
    "########\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model1 = load_model('saved_models/model1.hdf5')\n",
    "model2 = load_model('saved_models/model2.hdf5')\n",
    "model3 = load_model('saved_models/model3.hdf5')\n",
    "\n",
    "models = [model1, model2, model3]\n",
    "\n",
    "preds = [model.predict(X_test) for model in models]\n",
    "preds=np.array(preds)\n",
    "summed = np.sum(preds, axis=0)\n",
    "\n",
    "# argmax across classes\n",
    "ensemble_prediction = np.argmax(summed, axis=1)\n",
    "\n",
    "prediction1 = model1.predict_classes(X_test)\n",
    "prediction2 = model2.predict_classes(X_test)\n",
    "prediction3 = model3.predict_classes(X_test)\n",
    "\n",
    "accuracy1 = accuracy_score(y_test, prediction1)\n",
    "accuracy2 = accuracy_score(y_test, prediction2)\n",
    "accuracy3 = accuracy_score(y_test, prediction3)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_prediction)\n",
    "\n",
    "print('Accuracy Score for model1 = ', accuracy1)\n",
    "print('Accuracy Score for model2 = ', accuracy2)\n",
    "print('Accuracy Score for model3 = ', accuracy3)\n",
    "print('Accuracy Score for average ensemble = ', ensemble_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#Weighted average ensemble\n",
    "models = [model1, model2, model3]\n",
    "preds = [model.predict(X_test) for model in models]\n",
    "preds=np.array(preds)\n",
    "weights = [0.4, 0.2, 0.4]\n",
    "\n",
    "#Use tensordot to sum the products of all elements over specified axes.\n",
    "weighted_preds = np.tensordot(preds, weights, axes=((0),(0)))\n",
    "weighted_ensemble_prediction = np.argmax(weighted_preds, axis=1)\n",
    "\n",
    "weighted_accuracy = accuracy_score(y_test, weighted_ensemble_prediction)\n",
    "\n",
    "print('Accuracy Score for model1 = ', accuracy1)\n",
    "print('Accuracy Score for model2 = ', accuracy2)\n",
    "print('Accuracy Score for model3 = ', accuracy3)\n",
    "print('Accuracy Score for average ensemble = ', ensemble_accuracy)\n",
    "print('Accuracy Score for weighted average ensemble = ', weighted_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#Grid search for the best combination of w1, w2, w3 that gives maximum acuracy\n",
    "models = [model1, model2, model3]\n",
    "preds1 = [model.predict(X_test) for model in models]\n",
    "preds1=np.array(preds1)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([])\n",
    "\n",
    "for w1 in range(0, 5):\n",
    "    for w2 in range(0,5):\n",
    "        for w3 in range(0,5):\n",
    "            wts = [w1/10.,w2/10.,w3/10.]\n",
    "            wted_preds1 = np.tensordot(preds1, wts, axes=((0),(0)))\n",
    "            wted_ensemble_pred = np.argmax(wted_preds1, axis=1)\n",
    "            weighted_accuracy = accuracy_score(y_test, wted_ensemble_pred)\n",
    "            df = df.append(pd.DataFrame({'wt1':wts[0],'wt2':wts[1], \n",
    "                                         'wt3':wts[2], 'acc':weighted_accuracy*100}, index=[0]), ignore_index=True)\n",
    "            \n",
    "max_acc_row = df.iloc[df['acc'].idxmax()]\n",
    "print(\"Max accuracy of \", max_acc_row[0], \" obained with w1=\", max_acc_row[1],\n",
    "      \" w2=\", max_acc_row[2], \" and w3=\", max_acc_row[3])         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "### Explore metrics for the ideal weighted ensemble model. \n",
    "\n",
    "models = [model1, model2, model3]\n",
    "preds = [model.predict(X_test) for model in models]\n",
    "preds=np.array(preds)\n",
    "ideal_weights = [0.4, 0.1, 0.2] \n",
    "\n",
    "#Use tensordot to sum the products of all elements over specified axes.\n",
    "ideal_weighted_preds = np.tensordot(preds, ideal_weights, axes=((0),(0)))\n",
    "ideal_weighted_ensemble_prediction = np.argmax(ideal_weighted_preds, axis=1)\n",
    "\n",
    "ideal_weighted_accuracy = accuracy_score(y_test, ideal_weighted_ensemble_prediction)\n",
    "\n",
    "\n",
    "\n",
    "i = random.randint(1,len(ideal_weighted_ensemble_prediction))\n",
    "plt.imshow(X_test[i,:,:,0]) \n",
    "print(\"Predicted Label: \", class_names[int(ideal_weighted_ensemble_prediction[i])])\n",
    "print(\"True Label: \", class_names[int(y_test[i])])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "#Print confusion matrix\n",
    "cm = confusion_matrix(y_test, ideal_weighted_ensemble_prediction)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.set(font_scale=1.6)\n",
    "sns.heatmap(cm, annot=True, linewidths=.5, ax=ax)\n",
    "\n",
    "\n",
    "#PLot fractional incorrect misclassifications\n",
    "incorr_fraction = 1 - np.diag(cm) / np.sum(cm, axis=1)\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "plt.bar(np.arange(24), incorr_fraction)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Fraction of incorrect predictions')\n",
    "plt.xticks(np.arange(24), class_names) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d449c2c9719e46da8888711fe96c496f7e1028614b94eda1e133a380157fa6b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
